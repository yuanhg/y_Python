{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "02_6eOfVirrd"
   },
   "source": [
    "# 1. Importing and preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "QxBVxifDirre",
    "outputId": "da070e7d-3b41-4f67-a511-c7167acfcf19"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# IMPORTS\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D, Activation, LeakyReLU\n",
    "from keras.layers.noise import AlphaDropout\n",
    "from keras.utils.generic_utils import get_custom_objects\n",
    "from keras import backend as K\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# LOAD DATA\n",
    "train_data = np.load('add_02.npz')\n",
    "x_train = train_data['x']\n",
    "y_train = train_data['y']\n",
    "\n",
    "#print(x_train)\n",
    "#print(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LFHysNzOirrg"
   },
   "source": [
    "# 2. Readying functions and hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 122
    },
    "colab_type": "code",
    "id": "vnZXfS8Pirrh",
    "outputId": "bdc3479e-c344-4562-f58c-5ff7abb22420"
   },
   "outputs": [],
   "source": [
    "# Readying neural network model\n",
    "def build_cnn(activation, dropout_rate, optimizer):\n",
    "    model = Sequential()\n",
    "    #model.add(Dropout(0.2))\n",
    "    model.add(Dense(32, input_shape=(3,))) \n",
    "    model.add(Activation(activation))\n",
    "    #model.add(Dropout(0.1))\n",
    "    model.add(Dense(1, activation='softmax'))\n",
    "    \n",
    "    model.compile(\n",
    "        loss='binary_crossentropy', #损失函数（loss function），模型要将其最小化，可以通过字符串标识符/目标函数指定\n",
    "        optimizer=optimizer, #优化器（opyimizer）,可以是优化器的字符串标识符，也可以是Optimizer类的实例\n",
    "        metrics=['accuracy'] #指标（metricts）列表， 对于任何分类问题，需要将其设置为metrics = [‘accuracy’]\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Add the GELU function to Keras\n",
    "def gelu(x):\n",
    "    return 0.5 * x * (1 + tf.tanh(tf.sqrt(2 / np.pi) * (x + 0.044715 * tf.pow(x, 3))))\n",
    "get_custom_objects().update({'gelu': Activation(gelu)})\n",
    "\n",
    "#act_func = ['sigmoid', 'relu', 'elu', 'leaky-relu', 'selu', 'gelu']\n",
    "act_func = ['sigmoid']#扩展型指数线性单元激活函数（SELU）高斯误差线性单元激活函数（GELU）"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "5P8bYt1-irrj"
   },
   "source": [
    "# 3. Fitting the data with multiple activation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "fuf01NfPirrk",
    "outputId": "7679883e-0de1-4dae-8f6d-4abc2b80f1fa"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with -->sigmoid<-- activation function\n",
      "\n",
      "Epoch 1/100\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 2/100\n",
      "7/7 [==============================] - 0s 285us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 3/100\n",
      "7/7 [==============================] - 0s 570us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 4/100\n",
      "7/7 [==============================] - 0s 285us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 5/100\n",
      "7/7 [==============================] - 0s 432us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 6/100\n",
      "7/7 [==============================] - 0s 570us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 7/100\n",
      "7/7 [==============================] - 0s 570us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 8/100\n",
      "7/7 [==============================] - 0s 145us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 9/100\n",
      "7/7 [==============================] - 0s 142us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 10/100\n",
      "7/7 [==============================] - 0s 285us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 11/100\n",
      "7/7 [==============================] - 0s 427us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 12/100\n",
      "7/7 [==============================] - 0s 283us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 13/100\n",
      "7/7 [==============================] - 0s 284us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 14/100\n",
      "7/7 [==============================] - 0s 285us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 15/100\n",
      "7/7 [==============================] - 0s 288us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 16/100\n",
      "7/7 [==============================] - 0s 285us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 17/100\n",
      "7/7 [==============================] - 0s 285us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 18/100\n",
      "7/7 [==============================] - 0s 285us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 19/100\n",
      "7/7 [==============================] - 0s 428us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 20/100\n",
      "7/7 [==============================] - 0s 428us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 21/100\n",
      "7/7 [==============================] - 0s 427us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 22/100\n",
      "7/7 [==============================] - 0s 285us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 23/100\n",
      "7/7 [==============================] - 0s 285us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 24/100\n",
      "7/7 [==============================] - 0s 427us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 25/100\n",
      "7/7 [==============================] - 0s 142us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 26/100\n",
      "7/7 [==============================] - 0s 285us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 27/100\n",
      "7/7 [==============================] - 0s 571us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 28/100\n",
      "7/7 [==============================] - 0s 283us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 29/100\n",
      "7/7 [==============================] - 0s 285us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 30/100\n",
      "7/7 [==============================] - 0s 568us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 31/100\n",
      "7/7 [==============================] - 0s 285us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 32/100\n",
      "7/7 [==============================] - 0s 285us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 33/100\n",
      "7/7 [==============================] - 0s 570us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 34/100\n",
      "7/7 [==============================] - 0s 285us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 35/100\n",
      "7/7 [==============================] - 0s 142us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 36/100\n",
      "7/7 [==============================] - 0s 143us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 37/100\n",
      "7/7 [==============================] - 0s 285us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 38/100\n",
      "7/7 [==============================] - 0s 285us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 39/100\n",
      "7/7 [==============================] - 0s 285us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 40/100\n",
      "7/7 [==============================] - 0s 283us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 41/100\n",
      "7/7 [==============================] - 0s 285us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 42/100\n",
      "7/7 [==============================] - 0s 285us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 43/100\n",
      "7/7 [==============================] - 0s 285us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 44/100\n",
      "7/7 [==============================] - 0s 424us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 45/100\n",
      "7/7 [==============================] - 0s 140us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 46/100\n",
      "7/7 [==============================] - 0s 287us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 47/100\n",
      "7/7 [==============================] - 0s 427us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 48/100\n",
      "7/7 [==============================] - 0s 285us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 49/100\n",
      "7/7 [==============================] - 0s 143us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 50/100\n",
      "7/7 [==============================] - 0s 284us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 51/100\n",
      "7/7 [==============================] - 0s 429us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 52/100\n",
      "7/7 [==============================] - 0s 286us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 53/100\n",
      "7/7 [==============================] - 0s 143us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 54/100\n",
      "7/7 [==============================] - 0s 285us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 55/100\n",
      "7/7 [==============================] - 0s 285us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 56/100\n",
      "7/7 [==============================] - 0s 289us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 57/100\n",
      "7/7 [==============================] - 0s 285us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 58/100\n",
      "7/7 [==============================] - 0s 283us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 59/100\n",
      "7/7 [==============================] - 0s 285us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 60/100\n",
      "7/7 [==============================] - 0s 285us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 61/100\n",
      "7/7 [==============================] - 0s 143us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 62/100\n",
      "7/7 [==============================] - 0s 285us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 63/100\n",
      "7/7 [==============================] - 0s 286us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 64/100\n",
      "7/7 [==============================] - 0s 428us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 65/100\n",
      "7/7 [==============================] - 0s 427us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 66/100\n",
      "7/7 [==============================] - 0s 141us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 67/100\n",
      "7/7 [==============================] - 0s 285us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 68/100\n",
      "7/7 [==============================] - 0s 285us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 69/100\n",
      "7/7 [==============================] - 0s 285us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 70/100\n",
      "7/7 [==============================] - 0s 285us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 71/100\n",
      "7/7 [==============================] - 0s 285us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 72/100\n",
      "7/7 [==============================] - 0s 286us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 73/100\n",
      "7/7 [==============================] - 0s 427us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 74/100\n",
      "7/7 [==============================] - 0s 285us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 75/100\n",
      "7/7 [==============================] - 0s 285us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 76/100\n",
      "7/7 [==============================] - 0s 428us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 77/100\n",
      "7/7 [==============================] - 0s 427us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 78/100\n",
      "7/7 [==============================] - 0s 283us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 79/100\n",
      "7/7 [==============================] - 0s 143us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 80/100\n",
      "7/7 [==============================] - 0s 285us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 81/100\n",
      "7/7 [==============================] - 0s 142us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 82/100\n",
      "7/7 [==============================] - 0s 133us/step - loss: 6.5714 - accuracy: 0.5714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 83/100\n",
      "7/7 [==============================] - 0s 285us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 84/100\n",
      "7/7 [==============================] - 0s 285us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 85/100\n",
      "7/7 [==============================] - 0s 570us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 86/100\n",
      "7/7 [==============================] - 0s 285us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 87/100\n",
      "7/7 [==============================] - 0s 285us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 88/100\n",
      "7/7 [==============================] - 0s 285us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 89/100\n",
      "7/7 [==============================] - 0s 288us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 90/100\n",
      "7/7 [==============================] - 0s 285us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 91/100\n",
      "7/7 [==============================] - 0s 285us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 92/100\n",
      "7/7 [==============================] - 0s 427us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 93/100\n",
      "7/7 [==============================] - 0s 570us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 94/100\n",
      "7/7 [==============================] - 0s 428us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 95/100\n",
      "7/7 [==============================] - 0s 287us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 96/100\n",
      "7/7 [==============================] - 0s 285us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 97/100\n",
      "7/7 [==============================] - 0s 285us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 98/100\n",
      "7/7 [==============================] - 0s 286us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 99/100\n",
      "7/7 [==============================] - 0s 285us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "Epoch 100/100\n",
      "7/7 [==============================] - 0s 143us/step - loss: 6.5714 - accuracy: 0.5714\n",
      "[<keras.callbacks.callbacks.History object at 0x00000282E01C8208>]\n"
     ]
    }
   ],
   "source": [
    "result = []\n",
    "\n",
    "for activation in act_func:\n",
    "    print('\\nTraining with -->{0}<-- activation function\\n'.format(activation))\n",
    "    \n",
    "    model = build_cnn(activation=activation,\n",
    "                      dropout_rate=0.2,\n",
    "                      optimizer=Adam(clipvalue=0.5))\n",
    "    '''\n",
    "    model.fit(x=None, y=None, \n",
    "        batch_size=None, \n",
    "        epochs=1, \n",
    "        verbose=1, \n",
    "        callbacks=None, \n",
    "        validation_split=0.0, validation_data=None, \n",
    "        shuffle=True, \n",
    "        class_weight=None, sample_weight=None, \n",
    "        initial_epoch=0, steps_per_epoch=None, validation_steps=None, validation_freq=1)\n",
    "    '''\n",
    "    history = model.fit(x_train, y_train, \n",
    "                        batch_size=None, # 128 is faster, but less accurate. 16/32 recommended\n",
    "                        epochs=100,\n",
    "                        verbose=1,\n",
    "                        validation_split=0.0,\n",
    "                        validation_data=None ) \n",
    "    \n",
    "    result.append(history)\n",
    "    \n",
    "    K.clear_session()\n",
    "    del model\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "clEHQS7cirrm"
   },
   "source": [
    "# 4. Graph the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "JYonCTctirrn",
    "outputId": "6867361f-96d4-4572-a1fc-9d8af9ced67d"
   },
   "outputs": [],
   "source": [
    "def plot_act_func_results(results, activation_functions = []):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.style.use('dark_background')\n",
    "    \n",
    "    # Plot validation accuracy values\n",
    "    for act_func in results:\n",
    "        plt.plot(act_func.history['val_acc'])\n",
    "        \n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('Test Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(activation_functions)\n",
    "    plt.show()\n",
    "\n",
    "    # Plot validation loss values\n",
    "    plt.figure(figsize=(10,10))\n",
    "    \n",
    "    for act_func in results:\n",
    "        plt.plot(act_func.history['val_loss'])\n",
    "        \n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Test Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(activation_functions)\n",
    "    plt.show()\n",
    "\n",
    "plot_act_func_results(result, act_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "aqeT_lC-irrp",
    "outputId": "d0903964-138c-4444-d8bb-613c58eaa11a"
   },
   "outputs": [],
   "source": [
    "new_act_arr = act_func[1:]\n",
    "new_results = result[1:]\n",
    "\n",
    "def plot_act_func_results(results, activation_functions = []):\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.style.use('dark_background')\n",
    "    \n",
    "    # Plot validation accuracy values\n",
    "    for act_func in results:\n",
    "        plt.plot(act_func.history['val_acc'])\n",
    "        \n",
    "    plt.title('Model accuracy')\n",
    "    plt.ylabel('Test Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(activation_functions)\n",
    "    plt.show()\n",
    "\n",
    "    # Plot validation loss values\n",
    "    plt.figure(figsize=(10,10))\n",
    "    \n",
    "    for act_func in results:\n",
    "        plt.plot(act_func.history['val_loss'])\n",
    "        \n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Test Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(activation_functions)\n",
    "    plt.show()\n",
    "\n",
    "plot_act_func_results(new_results, new_act_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "aqeT_lC-irrp",
    "outputId": "d0903964-138c-4444-d8bb-613c58eaa11a"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "aqeT_lC-irrp",
    "outputId": "d0903964-138c-4444-d8bb-613c58eaa11a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 1]\n",
      " [0 1 1]\n",
      " [1 0 1]\n",
      " [0 1 0]\n",
      " [1 0 0]\n",
      " [1 1 1]\n",
      " [0 0 0]]\n",
      "[[0]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [1]\n",
      " [0]\n",
      " [0]]\n",
      "[[1 0 0]]\n",
      "[[1]]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# the training inputs \n",
    "# the last column is used to add non linearity to the clasification task\n",
    "x = np.array([[0, 0, 1],\n",
    "              [0, 1, 1],\n",
    "              [1, 0, 1],\n",
    "              [0, 1, 0],\n",
    "              [1, 0, 0],\n",
    "              [1, 1, 1],\n",
    "              [0, 0, 0]])\n",
    "    \n",
    "# the training outputs\n",
    "y = np.array([[0, 1, 1, 1, 1, 0, 0]]).T\n",
    "\n",
    "np.savez('add_date.npz', x=x, y=y)\n",
    "train_data = np.load('add_date.npz')\n",
    "print(train_data['x'])\n",
    "print(train_data['y'])\n",
    "\n",
    "# the test inputs \n",
    "# the last column is used to add non linearity to the clasification task\n",
    "x = np.array([[1, 0, 0]])\n",
    "    \n",
    "# the training outputs\n",
    "y = np.array([[1]]).T\n",
    "\n",
    "np.savez('add_date_t.npz', x=x, y=y)\n",
    "test_data = np.load('add_date_t.npz')\n",
    "print(test_data['x'])\n",
    "print(test_data['y'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "name": "Experiment_Activation_Functions.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
